{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Linear Discriminant  for IRIS Dataset Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv3YhajuYr6M",
        "colab_type": "text"
      },
      "source": [
        "## Linear Model to Classify Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dD_Yrk7F_B2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5840b2d-1ddc-455c-a386-54a0ce4fe19f"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import keras\n",
        "np.random.seed(10)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlcFqSsIZgY2",
        "colab_type": "text"
      },
      "source": [
        "### Loading the Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SIuFGjzGY7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5d04f07-9092-4b80-97ce-1609401ee949"
      },
      "source": [
        "iris = load_iris()\n",
        "print(iris.keys())\n",
        "X = iris['data']   # array([[5.1, 3.5, 1.4, 0.2], [4.9, 3. , 1.4, 0.2], ... ])\n",
        "Y = iris['target'] # array([0, 1, 2, 0, ... ])\n",
        "names = iris['target_names']  #['setosa', 'versicolor', 'virginica']\n",
        "feature_names = iris['feature_names']  # ['sepal length (cm)', \n",
        "                                        # 'sepal width (cm)', \n",
        "                                        # 'petal length (cm)', \n",
        "                                        # 'petal width (cm)']\n",
        "# To Track a few sample points\n",
        "isamples = np.random.randint(len(Y), size = (5))\n",
        "                   # array([ 9, 125, 15, 64, 113]) <-- random samples (example)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut1tQNcFI_97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "a0d74102-6d2c-4cd8-f054-73a4e4903741"
      },
      "source": [
        "print(X.shape, Y.shape)\n",
        "print(X[isamples])\n",
        "print(Y[isamples])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4) (150,)\n",
            "[[4.9 3.1 1.5 0.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [5.7 2.5 5.  2. ]]\n",
            "[0 2 0 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVGE7d-UZkBK",
        "colab_type": "text"
      },
      "source": [
        "### Categorial One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1UC_9IeJuVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "ff46ff57-377b-419d-e1bc-f0e31916dbbe"
      },
      "source": [
        "# Convert lables to categorial one-hot encoding\n",
        "Ny = len(np.unique(Y))  # Ny = 3\n",
        "Y = keras.utils.to_categorical(Y[:], num_classes = Ny)\n",
        "# Y is np.ndarray now\n",
        "print(\"X:\", X[isamples, :])\n",
        "print(\"Y:\", Y[isamples])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: [[4.9 3.1 1.5 0.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [5.7 2.5 5.  2. ]]\n",
            "Y: [[1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzAzocFxY93J",
        "colab_type": "text"
      },
      "source": [
        "### Train Test Split (randomly into 80% - 20%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3kXht1cKuqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4e129ed9-e019-40d6-ae33-6f6babdae93e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
        "                            test_size = 0.20, random_state = 1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 4)\n",
            "(30, 4)\n",
            "(120, 3)\n",
            "(30, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mFSkUEzZHlo",
        "colab_type": "text"
      },
      "source": [
        "### Data Normalization: Zero-Mean & Unit-Variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PUyhphZLwfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84456d84-1fea-4b1a-d4e0-1fb91d6664db"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # computes mean and std\n",
        "X_train = scaler.transform(X_train)  # x = (x-mean)/std\n",
        "X_test = scaler.transform(X_test)\n",
        "print(X_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.31553662 -0.04578885  0.44767531  0.23380268]\n",
            " [ 2.2449325  -0.04578885  1.29769171  1.39742892]\n",
            " [-0.2873996  -1.24028061  0.05100098 -0.15407273]\n",
            " [ 0.67729835 -0.52358555  1.01435291  1.13884531]\n",
            " [-0.04622511 -0.52358555  0.73101411  1.52672073]\n",
            " [-0.64916132  1.62649961 -1.30902526 -1.31769898]\n",
            " [-0.40798684 -1.71807731  0.10766874  0.10451088]\n",
            " [-0.76974857  0.90980456 -1.36569302 -1.31769898]\n",
            " [ 0.79788559 -0.52358555  0.44767531  0.36309449]\n",
            " [ 1.03906007 -1.24028061  1.12768843  0.7509699 ]\n",
            " [ 1.15964732 -0.04578885  0.95768515  1.13884531]\n",
            " [-0.89033581  1.14870291 -1.36569302 -1.18840717]\n",
            " [ 0.19494938 -1.95697567  0.67434635  0.36309449]\n",
            " [ 0.5567111  -0.2846872   1.01435291  0.7509699 ]\n",
            " [ 0.91847283 -0.2846872   0.44767531  0.10451088]\n",
            " [ 2.2449325  -1.00138226  1.75103379  1.39742892]\n",
            " [-0.16681235  1.86539796 -1.19568974 -1.18840717]\n",
            " [-1.01092305  1.38760126 -1.36569302 -1.31769898]\n",
            " [-1.25209754 -0.04578885 -1.36569302 -1.18840717]\n",
            " [-0.76974857 -0.76248391  0.05100098  0.23380268]\n",
            " [-0.89033581  0.90980456 -1.30902526 -1.31769898]\n",
            " [-0.40798684  1.14870291 -1.42236078 -1.31769898]\n",
            " [ 2.2449325   1.86539796  1.63769827  1.26813712]\n",
            " [ 1.28023456  0.1931095   0.90101739  1.13884531]\n",
            " [ 1.76258353 -0.2846872   1.41102723  0.7509699 ]\n",
            " [ 0.67729835 -0.52358555  1.01435291  1.26813712]\n",
            " [ 0.43612386 -0.52358555  0.56101083  0.7509699 ]\n",
            " [ 0.19494938  0.90980456  0.39100755  0.49238629]\n",
            " [ 2.2449325  -0.52358555  1.63769827  1.00955351]\n",
            " [-0.16681235 -0.04578885  0.22100426 -0.02478093]\n",
            " [-1.25209754  0.90980456 -1.2523575  -1.31769898]\n",
            " [-0.16681235 -1.24028061  0.67434635  1.00955351]\n",
            " [ 0.5567111  -0.76248391  0.61767859  0.7509699 ]\n",
            " [-1.25209754 -0.04578885 -1.36569302 -1.44699078]\n",
            " [-1.37268478  0.43200785 -1.42236078 -1.31769898]\n",
            " [ 0.79788559 -0.04578885  1.12768843  1.26813712]\n",
            " [-1.49327202  0.90980456 -1.36569302 -1.18840717]\n",
            " [ 0.31553662 -0.04578885  0.61767859  0.7509699 ]\n",
            " [ 0.79788559  0.43200785  0.73101411  1.00955351]\n",
            " [ 1.03906007  0.1931095   0.33433978  0.23380268]\n",
            " [-0.16681235 -0.52358555  0.39100755  0.10451088]\n",
            " [ 1.03906007  0.6709062   1.07102067  1.65601253]\n",
            " [ 0.19494938 -0.04578885  0.56101083  0.7509699 ]\n",
            " [-0.89033581  1.86539796 -1.2523575  -1.31769898]\n",
            " [ 0.19494938 -1.95697567  0.10766874 -0.28336454]\n",
            " [ 0.67729835 -0.2846872   0.27767202  0.10451088]\n",
            " [ 0.79788559 -0.04578885  0.95768515  0.7509699 ]\n",
            " [-1.01092305 -1.71807731 -0.28900558 -0.28336454]\n",
            " [ 0.5567111   0.6709062   1.24102395  1.65601253]\n",
            " [-0.40798684 -1.24028061  0.10766874  0.10451088]\n",
            " [-0.52857408  1.62649961 -1.30902526 -1.31769898]\n",
            " [-1.13151029  0.1931095  -1.30902526 -1.31769898]\n",
            " [-0.76974857  2.58209302 -1.30902526 -1.44699078]\n",
            " [ 1.03906007  0.6709062   1.07102067  1.13884531]\n",
            " [-1.73444651 -0.04578885 -1.42236078 -1.31769898]\n",
            " [ 0.19494938 -0.76248391  0.73101411  0.49238629]\n",
            " [ 0.67729835 -0.76248391  0.84434963  0.8802617 ]\n",
            " [ 0.07436213 -0.04578885  0.73101411  0.7509699 ]\n",
            " [-0.76974857  1.14870291 -1.30902526 -1.31769898]\n",
            " [-0.89033581  0.6709062  -1.19568974 -0.92982356]\n",
            " [-0.04622511 -0.76248391  0.1643365  -0.28336454]\n",
            " [-1.13151029  0.1931095  -1.30902526 -1.44699078]\n",
            " [ 1.88317077 -0.52358555  1.29769171  0.8802617 ]\n",
            " [ 0.43612386 -0.2846872   0.27767202  0.10451088]\n",
            " [ 2.12434526 -0.04578885  1.58103051  1.13884531]\n",
            " [ 1.03906007 -0.04578885  0.78768187  1.39742892]\n",
            " [ 0.5567111  -1.71807731  0.33433978  0.10451088]\n",
            " [ 0.43612386  0.90980456  0.90101739  1.39742892]\n",
            " [ 1.64199629  1.38760126  1.29769171  1.65601253]\n",
            " [-0.2873996  -0.2846872  -0.1190023   0.10451088]\n",
            " [-0.16681235  3.29878808 -1.30902526 -1.05911537]\n",
            " [-0.04622511 -0.76248391  0.05100098 -0.02478093]\n",
            " [-1.61385927 -1.71807731 -1.42236078 -1.18840717]\n",
            " [-0.40798684 -1.47917896 -0.00566678 -0.15407273]\n",
            " [ 1.28023456  0.1931095   0.61767859  0.36309449]\n",
            " [-1.01092305  0.90980456 -1.2523575  -1.05911537]\n",
            " [ 1.15964732 -0.52358555  0.56101083  0.23380268]\n",
            " [-1.01092305  1.14870291 -1.2523575  -0.80053176]\n",
            " [-1.25209754  0.90980456 -1.08235422 -1.31769898]\n",
            " [ 0.5567111   0.90980456  1.01435291  1.52672073]\n",
            " [-0.2873996  -0.52358555  0.61767859  1.00955351]\n",
            " [ 1.15964732  0.43200785  1.18435619  1.39742892]\n",
            " [-1.01092305  0.6709062  -1.36569302 -1.31769898]\n",
            " [-0.89033581  1.62649961 -1.30902526 -1.05911537]\n",
            " [ 0.07436213  0.43200785  0.56101083  0.7509699 ]\n",
            " [-1.49327202  0.1931095  -1.30902526 -1.31769898]\n",
            " [-0.04622511 -0.76248391  0.73101411  0.8802617 ]\n",
            " [-1.25209754  0.1931095  -1.2523575  -1.31769898]\n",
            " [ 0.79788559 -0.04578885  0.78768187  1.00955351]\n",
            " [-1.13151029 -1.24028061  0.39100755  0.62167809]\n",
            " [-1.49327202  0.43200785 -1.36569302 -1.31769898]\n",
            " [ 0.67729835  0.43200785  0.84434963  1.39742892]\n",
            " [-1.85503375 -0.04578885 -1.5356963  -1.44699078]\n",
            " [-0.2873996  -0.04578885  0.1643365   0.10451088]\n",
            " [-1.73444651 -0.2846872  -1.36569302 -1.31769898]\n",
            " [-0.40798684 -1.47917896 -0.06233454 -0.28336454]\n",
            " [-1.01092305 -2.43477237 -0.17567006 -0.28336454]\n",
            " [-0.89033581  1.14870291 -1.36569302 -1.31769898]\n",
            " [-1.13151029 -0.04578885 -1.36569302 -1.31769898]\n",
            " [-1.13151029 -1.47917896 -0.28900558 -0.28336454]\n",
            " [-1.49327202  1.38760126 -1.59236406 -1.31769898]\n",
            " [ 0.07436213 -0.04578885  0.22100426  0.36309449]\n",
            " [ 0.31553662 -0.2846872   0.50434307  0.23380268]\n",
            " [-1.01092305  0.90980456 -1.30902526 -1.31769898]\n",
            " [ 1.03906007  0.1931095   0.50434307  0.36309449]\n",
            " [-0.16681235 -0.2846872   0.22100426  0.10451088]\n",
            " [ 0.43612386 -1.95697567  0.39100755  0.36309449]\n",
            " [ 1.4008218   0.43200785  0.50434307  0.23380268]\n",
            " [-0.04622511 -0.76248391  0.73101411  0.8802617 ]\n",
            " [-0.52857408  0.90980456 -1.19568974 -1.31769898]\n",
            " [-1.01092305 -0.04578885 -1.2523575  -1.31769898]\n",
            " [ 0.31553662 -1.00138226  1.01435291  0.23380268]\n",
            " [ 0.31553662 -0.52358555  0.10766874  0.10451088]\n",
            " [ 1.64199629 -0.04578885  1.12768843  0.49238629]\n",
            " [-0.16681235 -1.00138226 -0.17567006 -0.28336454]\n",
            " [ 0.5567111  -0.52358555  0.73101411  0.36309449]\n",
            " [ 0.67729835  0.1931095   0.95768515  0.7509699 ]\n",
            " [ 0.5567111  -1.24028061  0.61767859  0.36309449]\n",
            " [ 1.03906007  0.1931095   1.01435291  1.52672073]\n",
            " [-1.13151029  1.38760126 -1.36569302 -1.44699078]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-oqlfwSZtTo",
        "colab_type": "text"
      },
      "source": [
        "### Least Square Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx1zLAHYMnv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "ff776278-242a-4411-c2ff-e174e7e92cf0"
      },
      "source": [
        "# Training with XW = Y\n",
        "addlcol = lambda A: np.concatenate((A, np.ones((A.shape[0], 1))), axis = 1)\n",
        "Ns, Nx = X_train.shape  # 120, 4\n",
        "# XX = np.concatenate((X_train, np.ones((Ns, 1))), axis = 1)\n",
        "XX = addlcol(X_train)\n",
        "print(XX.shape)\n",
        "YY = Y_train\n",
        "print(YY.shape)\n",
        "W = np.linalg.inv(XX.T.dot(XX)).dot(XX.T.dot(YY))\n",
        "print(W)\n",
        "def evaluate(X, W, Yd):\n",
        "  ''' X is np.array (Nsamples, Nfeats);\n",
        "     Yd is np.array (Nsamples, Nonehot) '''\n",
        "  x = addlcol(X)\n",
        "  yd = np.argmax(Yd, axis = 1)\n",
        "  y = np.argmax(x.dot(W), axis = 1)\n",
        "  print(\"CM:\")\n",
        "  print(confusion_matrix(yd, y))\n",
        "evaluate(X_train, W, Y_train)\n",
        "evaluate(X_test, W, Y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 5)\n",
            "(120, 3)\n",
            "[[ 0.06062508  0.05806364 -0.11868873]\n",
            " [ 0.10258458 -0.21112954  0.10854496]\n",
            " [-0.4070331   0.22897614  0.17805695]\n",
            " [-0.03856453 -0.30252108  0.34108561]\n",
            " [ 0.325       0.30833333  0.36666667]]\n",
            "CM:\n",
            "[[39  0  0]\n",
            " [ 0 22 15]\n",
            " [ 0  4 40]]\n",
            "CM:\n",
            "[[11  0  0]\n",
            " [ 0  6  7]\n",
            " [ 0  0  6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Hg41JamF9t",
        "colab_type": "text"
      },
      "source": [
        "Since, in Lower-Dimension we are'nt able to separate the Data therefore, we now take the data to Higher Dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKv9qvPsO3C3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "3e6585bd-2684-4a9e-a8f6-b338a6fe7891"
      },
      "source": [
        "addSqlcol = lambda A: np.concatenate((A, A**2, \n",
        "                    np.ones((A.shape[0], 1))), axis = 1)\n",
        "Ns, Nx = X_train.shape  # 120, 4\n",
        "XX = addSqlcol(X_train)\n",
        "print(XX.shape)\n",
        "YY = Y_train\n",
        "print(YY.shape)\n",
        "W = np.linalg.inv(XX.T.dot(XX)).dot(XX.T.dot(YY))\n",
        "print(W)\n",
        "def evaluate(X, W, Yd):\n",
        "    '''  X is np.array (Nsamples, Nfeats);\n",
        "        Yd is np.array (Nsamples, Nonehot) '''\n",
        "    x = addSqlcol(X)\n",
        "    yd = np.argmax(Yd, axis = 1)\n",
        "    y = np.argmax(x.dot(W), axis = 1)\n",
        "    print(\"CM:\")\n",
        "    print(confusion_matrix(yd, y))\n",
        "evaluate(X_train, W, Y_train)\n",
        "evaluate(X_test, W, Y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 9)\n",
            "(120, 3)\n",
            "[[ 0.02212851  0.1284788  -0.15060731]\n",
            " [ 0.02261966  0.00396191 -0.02658157]\n",
            " [-0.31265762 -0.00385162  0.31650925]\n",
            " [-0.05916917 -0.24649968  0.30566885]\n",
            " [-0.03340995  0.13233974 -0.09892979]\n",
            " [-0.00993575  0.01269958 -0.00276383]\n",
            " [ 0.21451737 -0.58556233  0.37104496]\n",
            " [ 0.04009892 -0.0947794   0.05468048]\n",
            " [ 0.1137294   0.84363575  0.04263485]]\n",
            "CM:\n",
            "[[39  0  0]\n",
            " [ 0 35  2]\n",
            " [ 0  2 42]]\n",
            "CM:\n",
            "[[11  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0  6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J-NXMYQpmr-",
        "colab_type": "text"
      },
      "source": [
        "Thus we obtained very high accuracy on the IRIS Dataset & also see that Data is mostly Linearly Separable in Higher Dimensional Space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-H77IXTvfg3",
        "colab_type": "text"
      },
      "source": [
        "### Minimum Norm Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRrBRO5Nv_of",
        "colab_type": "text"
      },
      "source": [
        "### For Under-determined System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWWa7jEHosKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "7427708c-0a12-44f8-9d6b-bdec69e63200"
      },
      "source": [
        "addlcol = lambda A: np.concatenate((A, np.ones((A.shape[0], 1))), axis = 1)\n",
        "ind = np.random.choice(range(X_train.shape[0]), size = 12, replace = False)\n",
        "XX = X_train[ind, :]\n",
        "XX = addlcol(XX)\n",
        "YY = Y_train[ind, :]\n",
        "W = XX.T.dot(np.linalg.inv(XX.dot(XX.T)).T.dot(YY)) # <--- X' (X X')^(-1) Y\n",
        "print(W, XX.shape, YY.shape)\n",
        "def evaluate(X, W, Yd):\n",
        "  ''' X is np.array (Nsamples, Nfeats);\n",
        "     Yd is np.array (Nsamples, Nonehot) '''\n",
        "  x = addlcol(X)\n",
        "  yd = np.argmax(Yd, axis = 1)\n",
        "  y = np.argmax(x.dot(W), axis = 1)\n",
        "  print(\"CM:\")\n",
        "  print(confusion_matrix(yd, y))\n",
        "evaluate(X_train[ind, :], W, YY)\n",
        "evaluate(X_test, W, Y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.20961103  0.58704205 -0.51231043]\n",
            " [ 0.3852091  -3.00142755  1.30941257]\n",
            " [ 1.25120866 -3.41458449  2.13456555]\n",
            " [ 0.14802282  1.96431021 -1.77695432]\n",
            " [-0.703125    2.4375      0.5625    ]] (12, 5) (12, 3)\n",
            "CM:\n",
            "[[0 2 1]\n",
            " [0 6 1]\n",
            " [1 1 0]]\n",
            "CM:\n",
            "[[ 0  4  7]\n",
            " [ 0 11  2]\n",
            " [ 1  3  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LQwBDk-xOdM",
        "colab_type": "text"
      },
      "source": [
        "Since, we did'nt use the entire data in the Minimum Norm Soln $(n=12)$ therefore, we don't get high accuracy.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWCgsushxqlw",
        "colab_type": "text"
      },
      "source": [
        "### For Under-determined System, with Square Input Features too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "522yJoUyw4oZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "ec1254bb-8d00-44d1-c1b3-4caebbcd9830"
      },
      "source": [
        "addSqlcol = lambda A: np.concatenate((A, A**2, np.ones((A.shape[0], 1))), axis = 1)\n",
        "ind = np.random.choice(range(X_train.shape[0]), size = 25, replace = False)\n",
        "XX = X_train[ind, :]\n",
        "XX = addSqlcol(XX)\n",
        "YY = Y_train[ind, :]\n",
        "W = XX.T.dot(np.linalg.inv(XX.dot(XX.T)).T.dot(YY)) # <--- X' (X X')^(-1) Y\n",
        "print(W, XX.shape, YY.shape)\n",
        "def evaluate(X, W, Yd):\n",
        "  ''' X is np.array (Nsamples, Nfeats);\n",
        "     Yd is np.array (Nsamples, Nonehot) '''\n",
        "  x = addSqlcol(X)\n",
        "  yd = np.argmax(Yd, axis = 1)\n",
        "  y = np.argmax(x.dot(W), axis = 1)\n",
        "  print(\"CM:\")\n",
        "  print(confusion_matrix(yd, y))\n",
        "evaluate(X_train[ind, :], W, YY)\n",
        "evaluate(X_test, W, Y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3.47226748e-01  3.63760253e+00 -3.68230723e+00]\n",
            " [ 1.97234620e-01 -1.75836953e+01  1.65363723e+01]\n",
            " [ 5.33253777e-01  1.29454482e+01 -1.25762651e+01]\n",
            " [-6.50822476e-01  2.04649360e+00 -9.84502537e-01]\n",
            " [ 7.00586907e-03 -6.63301314e+00  7.72945840e+00]\n",
            " [-4.14679850e-01 -5.32558420e+00  4.52391144e+00]\n",
            " [ 2.48117879e-01 -1.05201103e+01  1.04398216e+01]\n",
            " [ 3.44167834e-01 -1.04225873e+01  1.08279327e+01]\n",
            " [-3.12500000e-01  8.59375000e+00 -5.56250000e+00]] (25, 9) (25, 3)\n",
            "CM:\n",
            "[[0 0 8]\n",
            " [0 6 0]\n",
            " [0 4 7]]\n",
            "CM:\n",
            "[[ 0  0 11]\n",
            " [ 0 12  1]\n",
            " [ 0  1  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frrIrkYuzLx4",
        "colab_type": "text"
      },
      "source": [
        "Since, we did'nt use the entire data in the Minimum Norm Soln $(n=25)$ therefore, we don't get high accuracy. There isn't any reason to use Minimum Norm Solution (since for IRIS Dataset we have already have large data) Thus Least Square Solution/ Pseudo- Inverse Soln. gives a Higher Accuracy.\n"
      ]
    }
  ]
}